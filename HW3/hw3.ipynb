{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "515840d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "from pathlib import Path\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label, regionprops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca469703",
   "metadata": {},
   "source": [
    "**Problem 1:** Generate a 3-level Gaussian pyramid (original image is level-0) and the corresponding\n",
    "Laplacian pyramid of an image (select one from the web, make it grayscale). Use the\n",
    "formula in the notes to first determine a viable image size (use N=3, and pick NC and\n",
    "NR), and crop the image (if needed) to test the pyramid code. Use a=0.4 for the\n",
    "Gaussian mask – use separable masks! Write/use functions for properly reducing and\n",
    "expanding an image. Write your own interpolation function - do not use\n",
    "Matlab/Python in-built interpolation functions (e.g., interp2). Lastly, perform a\n",
    "reconstruction of the original (cropped) image using the Laplacian pyramid. [8 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: image shape: (233, 313) levels: 3 a: 0.4\n",
      "Q1: reconstruction MSE = 1.808445915913163e-35\n",
      "w: [0.05 0.25 0.4  0.25 0.05]\n",
      "Cropped shape: (233, 313)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def make_gaussian_1d(a=0.4):\n",
    "    return np.array([0.25 - 0.5*a, 0.25, a, 0.25, 0.25 - 0.5*a], dtype=np.float64)\n",
    "\n",
    "def pad_reflect_1d(x, r):\n",
    "    # symmetric reflect including edge pixel:\n",
    "    # [a b c d], r=2 -> left=[b,a], right=[d,c]\n",
    "    left  = x[:r][::-1]\n",
    "    right = x[:-r-1:-1]\n",
    "    return np.concatenate([left, x, right], axis=0)\n",
    "\n",
    "def conv1d_along_axis(img, k, axis):\n",
    "    # Convolve along rows (axis=1) or cols (axis=0) with kernel k (odd length)\n",
    "    r = len(k)//2\n",
    "    if axis == 1:\n",
    "        out = np.zeros_like(img, dtype=np.float64)\n",
    "        for i in range(img.shape[0]):\n",
    "            row = pad_reflect_1d(img[i, :], r)\n",
    "            acc = np.zeros(img.shape[1], dtype=np.float64)\n",
    "            for t, kv in enumerate(k):\n",
    "                acc += kv * row[t:t+img.shape[1]]\n",
    "            out[i, :] = acc\n",
    "        return out\n",
    "    else:\n",
    "        # apply by transposing work to row case\n",
    "        return conv1d_along_axis(img.T, k, axis=1).T\n",
    "\n",
    "def gauss_blur_sep(im, w):\n",
    "    return conv1d_along_axis(conv1d_along_axis(im, w, axis=1), w, axis=0)\n",
    "\n",
    "def reduce(im, w):\n",
    "    blurred = gauss_blur_sep(im, w)\n",
    "    return blurred[::2, ::2]\n",
    "\n",
    "def upsample_zeros(im, target_shape):\n",
    "    H, W = target_shape\n",
    "    out = np.zeros((H, W), dtype=np.float64)\n",
    "    out[::2, ::2] = im\n",
    "    return out\n",
    "\n",
    "def expand(im_small, w, target_shape):\n",
    "    # zero-insert then low-pass with *scaled* kernel so DC is preserved after upsampling\n",
    "    up = upsample_zeros(im_small, target_shape)\n",
    "    w2 = 2.0 * w  # scale factor per 1D pass for correct interpolation energy\n",
    "    return gauss_blur_sep(up, w2)\n",
    "\n",
    "def gaussian_pyramid(im0, levels=3, a=0.4):\n",
    "    w = make_gaussian_1d(a)\n",
    "    G = [im0]\n",
    "    for _ in range(levels):\n",
    "        G.append(reduce(G[-1], w))\n",
    "    return G, w\n",
    "\n",
    "def laplacian_pyramid(G, w):\n",
    "    L = []\n",
    "    for k in range(len(G)-1):\n",
    "        Ek = expand(G[k+1], w, G[k].shape)\n",
    "        L.append(G[k] - Ek)\n",
    "    return L\n",
    "\n",
    "def reconstruct_from_laplacian(L, Gtop, w):\n",
    "    R = Gtop.copy()\n",
    "    for k in reversed(range(len(L))):\n",
    "        R = L[k] + expand(R, w, L[k].shape)\n",
    "    return R\n",
    "\n",
    "# ---- helpers for cropping to valid size (N=3) ----\n",
    "def crop_to_valid_size(im, N=3):\n",
    "    H, W = im.shape\n",
    "    f = 2**N\n",
    "    Hc = (H - 1) // f * f + 1\n",
    "    Wc = (W - 1) // f * f + 1\n",
    "    return im[:Hc, :Wc]\n",
    "\n",
    "def rgb2gray_ntsc(img_uint8):\n",
    "    # Expect HxWx3 uint8; return float64 in [0,1] using class formula\n",
    "    img = img_uint8.astype(np.float64) / 255.0\n",
    "    return 0.299*img[...,0] + 0.587*img[...,1] + 0.114*img[...,2]  # Y channel\n",
    "\n",
    "def rescale_for_display(im):\n",
    "    # For Laplacians: shift/scale to [0,1] for viewing\n",
    "    m, M = np.min(im), np.max(im)\n",
    "    return np.zeros_like(im) if M == m else (im - m) / (M - m)\n",
    "\n",
    "def run_q1(image_path, N=3, a=0.4, save_prefix=\"q1_\"):\n",
    "    # 1) load + gray\n",
    "    raw = imageio.imread(image_path)\n",
    "    if raw.ndim == 3:\n",
    "        g = rgb2gray_ntsc(raw)\n",
    "    else:\n",
    "        g = raw.astype(np.float64) / 255.0\n",
    "\n",
    "    # 2) crop to valid size R=MR*2^N+1, C=MC*2^N+1\n",
    "    g = crop_to_valid_size(g, N)\n",
    "\n",
    "    # 3) pyramids\n",
    "    G, w = gaussian_pyramid(g, levels=N, a=a)\n",
    "    L = laplacian_pyramid(G, w)\n",
    "\n",
    "    # 4) reconstruction + error\n",
    "    recon = reconstruct_from_laplacian(L, G[-1], w)\n",
    "    err   = recon - g\n",
    "    mse   = np.mean(err**2)\n",
    "    print(\"Q1: image shape:\", g.shape, \"levels:\", N, \"a:\", a)\n",
    "    print(\"Q1: reconstruction MSE =\", mse)\n",
    "\n",
    "    # 5) (optional) save PNGs to visually confirm\n",
    "    try:\n",
    "        imageio.imwrite(f\"{save_prefix}G0.png\", (np.clip(G[0],0,1)*255).astype(np.uint8))\n",
    "        for i in range(1, len(G)):\n",
    "            imageio.imwrite(f\"{save_prefix}G{i}.png\", (np.clip(G[i],0,1)*255).astype(np.uint8))\n",
    "        for i, Li in enumerate(L):\n",
    "            Vi = rescale_for_display(Li)\n",
    "            imageio.imwrite(f\"{save_prefix}L{i}.png\", (np.clip(Vi,0,1)*255).astype(np.uint8))\n",
    "        imageio.imwrite(f\"{save_prefix}recon.png\", (np.clip(recon,0,1)*255).astype(np.uint8))\n",
    "        Vi = rescale_for_display(err)\n",
    "        imageio.imwrite(f\"{save_prefix}error.png\", (np.clip(Vi,0,1)*255).astype(np.uint8))\n",
    "    except Exception as e:\n",
    "        print(\"Skipping image saves:\", e)\n",
    "\n",
    "    # 6) return for notebook inspection if needed\n",
    "    return G, L, recon, err, mse\n",
    "\n",
    "# Example usage (pseudo):\n",
    "# im = load_gray_float_image(...)   # range [0,1]\n",
    "# im = crop_to_valid_size(im, N=3)\n",
    "# G, w = gaussian_pyramid(im, levels=3, a=0.4)\n",
    "# L = laplacian_pyramid(G, w)\n",
    "# recon = reconstruct_from_laplacian(L, G[-1], w)\n",
    "# print(\"MSE:\", np.mean((recon - im)**2))\n",
    "G, L, recon, err, mse = run_q1(\"walk.bmp\", N=3, a=0.4, save_prefix=\"q1_\")\n",
    "w = make_gaussian_1d(0.4); print(\"w:\", w)\n",
    "print(\"Cropped shape:\", G[0].shape)  # insi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6545ec2",
   "metadata": {},
   "source": [
    "**Problem 2:** Using the grayscale images (walk.bmp, bg000.bmp) provided on the WWW site,\n",
    "perform background subtraction 1 (abs diff) to extract the object. Make sure your\n",
    "image is of type double! Experiment with thresholds and discuss. [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bef256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 shapes: I=(240, 320), R=(240, 320)  dtype=float64\n",
      "Manual thresholds: T=0.10 / 0.15 / 0.20\n",
      "Otsu threshold on |I-R| : 0.28515625\n",
      "    T=0.10  foreground pixels = 2885  (3.757%)\n",
      "    T=0.15  foreground pixels = 1937  (2.522%)\n",
      "    T=0.20  foreground pixels = 1671  (2.176%)\n",
      "Otsu=0.2852  foreground pixels = 1441  (1.876%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00392157, 0.00392157, 0.01568627, ..., 0.04313725, 0.00784314,\n",
       "         0.07058824],\n",
       "        [0.01176471, 0.00784314, 0.02745098, ..., 0.08627451, 0.01960784,\n",
       "         0.14117647],\n",
       "        ...,\n",
       "        [0.00784314, 0.05490196, 0.05098039, ..., 0.        , 0.00392157,\n",
       "         0.01176471],\n",
       "        [0.01960784, 0.08627451, 0.01960784, ..., 0.01176471, 0.01176471,\n",
       "         0.00784314],\n",
       "        [0.01960784, 0.08627451, 0.01960784, ..., 0.01176471, 0.01176471,\n",
       "         0.00784314]]),\n",
       " {'T=0.10': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       "  'T=0.15': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       "  'T=0.20': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       "  'T_otsu': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)},\n",
       " np.float64(0.28515625))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def to_float_gray(img):\n",
    "    # make sure image is double in [0,1]; if color slips in, convert to gray (NTSC)\n",
    "    if img.ndim == 3:\n",
    "        img = 0.299*img[...,0] + 0.587*img[...,1] + 0.114*img[...,2]  # Y channel\n",
    "    if img.dtype != np.float64:\n",
    "        img = img.astype(np.float64)\n",
    "    if img.max() > 1.0:\n",
    "        img /= 255.0\n",
    "    return img\n",
    "\n",
    "def load_pair(obj_path=\"walk.bmp\", bg_path=\"bg000.bmp\"):\n",
    "    I = to_float_gray(imageio.imread(obj_path))\n",
    "    R = to_float_gray(imageio.imread(bg_path))\n",
    "    # ensure same size (they should be)\n",
    "    H = min(I.shape[0], R.shape[0])\n",
    "    W = min(I.shape[1], R.shape[1])\n",
    "    return I[:H,:W], R[:H,:W]\n",
    "\n",
    "def abs_diff_mask(I, R, T):\n",
    "    D = np.abs(I - R)\n",
    "    return (D > T).astype(np.uint8), D\n",
    "\n",
    "def otsu_threshold01(D, nbins=256):\n",
    "    # Otsu on [0,1] difference image\n",
    "    hist, edges = np.histogram(D.ravel(), bins=nbins, range=(0.0,1.0))\n",
    "    hist = hist.astype(np.float64)\n",
    "    p = hist / hist.sum()\n",
    "    w_cum = np.cumsum(p)\n",
    "    mu_cum = np.cumsum(p * (edges[:-1] + edges[1:]) / 2.0)  # bin centers\n",
    "    mu_t = mu_cum[-1]\n",
    "    # between-class variance for each split\n",
    "    num = (mu_t * w_cum - mu_cum)**2\n",
    "    den = w_cum * (1.0 - w_cum)\n",
    "    sigma_b2 = np.where(den > 0, num/den, 0.0)\n",
    "    k = np.argmax(sigma_b2)\n",
    "    # threshold at the boundary after bin k\n",
    "    return edges[k+1]\n",
    "\n",
    "def run_q2(obj_path=\"walk.bmp\", bg_path=\"bg000.bmp\", save_prefix=\"q2_\"):\n",
    "    I, R = load_pair(obj_path, bg_path)\n",
    "    B_10, D = abs_diff_mask(I, R, 0.10)   # try a few manual T's\n",
    "    B_15, _ = abs_diff_mask(I, R, 0.15)\n",
    "    B_20, _ = abs_diff_mask(I, R, 0.20)\n",
    "    T_otsu = otsu_threshold01(D)\n",
    "    B_otsu, _ = abs_diff_mask(I, R, T_otsu)\n",
    "\n",
    "    print(f\"Q2 shapes: I={I.shape}, R={R.shape}  dtype={I.dtype}\")\n",
    "    print(\"Manual thresholds: T=0.10 / 0.15 / 0.20\")\n",
    "    print(\"Otsu threshold on |I-R| :\", T_otsu)\n",
    "    for name, B in [(\"T=0.10\", B_10), (\"T=0.15\", B_15), (\"T=0.20\", B_20), (f\"Otsu={T_otsu:.4f}\", B_otsu)]:\n",
    "        fg = int(B.sum())\n",
    "        print(f\"{name:>10}  foreground pixels = {fg}  ({fg / B.size:.3%})\")\n",
    "\n",
    "    # save helpful images for the report\n",
    "    try:\n",
    "        imageio.imwrite(f\"{save_prefix}diff.png\", (np.clip(D,0,1)*255).astype(np.uint8))\n",
    "        imageio.imwrite(f\"{save_prefix}mask_T010.png\", (B_10*255).astype(np.uint8))\n",
    "        imageio.imwrite(f\"{save_prefix}mask_T015.png\", (B_15*255).astype(np.uint8))\n",
    "        imageio.imwrite(f\"{save_prefix}mask_T020.png\", (B_20*255).astype(np.uint8))\n",
    "        imageio.imwrite(f\"{save_prefix}mask_otsu.png\", (B_otsu*255).astype(np.uint8))\n",
    "    except Exception as e:\n",
    "        print(\"Save skipped:\", e)\n",
    "\n",
    "    return D, {\"T=0.10\":B_10, \"T=0.15\":B_15, \"T=0.20\":B_20, \"T_otsu\":B_otsu}, T_otsu\n",
    "run_q2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bbc20",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "We did abs-diff exactly like the slides: D=∣I−R∣ then threshold; Otsu picked T≈0.285 (~73/255) for a tighter mask (~1.88% fg), while manual T=0.10/0.15/0.20 gave 3.76% / 2.52% / 2.18%, respectively. That tracks: the diff histogram is dominated by background near zero, so Otsu lands higher (more conservative), whereas lower T scoops up noise/shadows—the slides say to set T “above the noise level.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31b009",
   "metadata": {},
   "source": [
    "**Problem 3**: Using the grayscale images (walk.bmp, bg[000-029].bmp) provided on the WWW\n",
    "site, perform background subtraction 2 using statistical distances. Experiment with\n",
    "thresholds and discuss. [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82db7a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma (raw):   min=0.000000 median=0.008947 max=0.186374\n",
      "fraction at floor = 0.008125\n",
      "Q3 shapes: I=(240, 320), bg-cube=(30, 240, 320), dtype=float64\n",
      "T=2.5  foreground pixels = 9389  (12.225%)\n",
      "T=3.0  foreground pixels = 7074  (9.211%)\n"
     ]
    }
   ],
   "source": [
    "def run_q3(obj_path=\"walk.bmp\", bg_dir=\".\", save_prefix=\"q3_\",\n",
    "           thresholds=(2.5, 3.0), sigma_floor=1e-3):\n",
    "\n",
    "    def to_float_gray(img):\n",
    "        if img.ndim == 3:\n",
    "            img = 0.299*img[...,0] + 0.587*img[...,1] + 0.114*img[...,2]\n",
    "        img = img.astype(np.float64)\n",
    "        if img.max() > 1: img /= 255.0\n",
    "        return img\n",
    "\n",
    "    def load_bg_cube(bg_dir=\".\", fmt=\"bg%03d.bmp\", n=30):\n",
    "        stack = []\n",
    "        for i in range(n):\n",
    "            p = Path(bg_dir) / (fmt % i)\n",
    "            stack.append(to_float_gray(imageio.imread(p)))\n",
    "        return np.stack(stack, axis=0)  # (N,H,W)\n",
    "\n",
    "    # 1) load\n",
    "    I  = to_float_gray(imageio.imread(obj_path))\n",
    "    Im = load_bg_cube(bg_dir)  # (30,H,W)\n",
    "    H = min(I.shape[0], Im.shape[1]); W = min(I.shape[1], Im.shape[2])\n",
    "    I  = I[:H,:W]; Im = Im[:, :H, :W]\n",
    "\n",
    "    # 2) background model\n",
    "    mu = Im.mean(axis=0)\n",
    "    sigma_raw = Im.std(axis=0)\n",
    "    sigma = np.maximum(sigma_raw, sigma_floor)  # <- raised floor (default 1e-3)\n",
    "\n",
    "    # quick stats (nice for your write-up)\n",
    "    print(\"sigma (raw):   min={:.6f} median={:.6f} max={:.6f}\"\n",
    "          .format(sigma_raw.min(), np.median(sigma_raw), sigma_raw.max()))\n",
    "    print(\"fraction at floor =\", np.mean(sigma == sigma_floor))\n",
    "\n",
    "    # 3) z-score\n",
    "    D = np.abs(I - mu) / sigma\n",
    "\n",
    "    # 4) thresholds from discussion (defaults: 2.5, 3.0)\n",
    "    masks = {}\n",
    "    print(f\"Q3 shapes: I={I.shape}, bg-cube={Im.shape}, dtype={I.dtype}\")\n",
    "    for T in thresholds:\n",
    "        B = (D > T).astype(np.uint8)\n",
    "        masks[f\"T={T:.1f}\"] = B\n",
    "        fg = int(B.sum())\n",
    "        print(f\"T={T:.1f}  foreground pixels = {fg}  ({fg/B.size:.3%})\")\n",
    "\n",
    "    # 5) save visualizations (fix: cast to uint8)\n",
    "    try:\n",
    "        z = D / max(1e-8, np.percentile(D, 99))\n",
    "        imageio.imwrite(f\"{save_prefix}zscore.png\", (np.clip(z,0,1)*255).astype(np.uint8))\n",
    "        for name,B in masks.items():\n",
    "            tag = name.replace('=','').replace('.','')\n",
    "            imageio.imwrite(f\"{save_prefix}mask_{tag}.png\", (B*255).astype(np.uint8))\n",
    "        # also save your “chosen” mask (cleaner per discussion)\n",
    "        best_tag = f\"T={thresholds[-1]:.1f}\".replace('=','').replace('.','')\n",
    "        imageio.imwrite(f\"{save_prefix}mask_best.png\", (masks[f'T={thresholds[-1]:.1f}']*255).astype(np.uint8))\n",
    "    except Exception as e:\n",
    "        print(\"Save skipped:\", e)\n",
    "\n",
    "    return D, masks, mu, sigma\n",
    "D, masks, mu, sigma = run_q3(\"walk.bmp\", \".\", thresholds=(2.5,3.0), sigma_floor=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de031cb9",
   "metadata": {},
   "source": [
    "**Discussion**: We modeled per-pixel μ,σ from the 30 backgrounds and used the z-score D=∣I−μ∣/σ; thresholds T=2.5 and T=3.0 flagged 12.23% and 9.21% of pixels, respectively. That checks out: σ (median ≈ 0.00895) normalizes local flicker/noise, and with only ~0.81% of pixels at the 1e-3 floor, the higher T keeps mostly true foreground—so we’ll roll with T≈3.0 and tidy remaining speckle in Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf682b1",
   "metadata": {},
   "source": [
    "**Problem 4**: Dilate your best binary image resulting from problem 3 using:\n",
    "    from scipy import ndimage\n",
    "    d_bsIm = ndimage.binary_dilation(im, structure=np.ones((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cef7af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilation (3x3): foreground pixels 7074 -> 16233  (Δ=+9159)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False,  True,  True],\n",
       "       [False, False, False, ..., False,  True,  True],\n",
       "       [False, False, False, ..., False,  True,  True],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def run_q4(best_mask, save_prefix=\"q4_\"):\n",
    "    \"\"\"\n",
    "    best_mask: binary mask from Q3 (e.g., masks['T=3.0']), dtype uint8 or bool\n",
    "    \"\"\"\n",
    "    B = (best_mask > 0)  # ensure boolean\n",
    "    se = np.ones((3,3), dtype=bool)      # 3x3 structuring element (square)\n",
    "    d_bsIm = ndimage.binary_dilation(B, structure=se)  # HW-instructed op\n",
    "\n",
    "    # quick stats for your write-up\n",
    "    before = int(B.sum()); after = int(d_bsIm.sum())\n",
    "    print(f\"Dilation (3x3): foreground pixels {before} -> {after}  (Δ={after-before:+d})\")\n",
    "\n",
    "    # save result\n",
    "    try:\n",
    "        imageio.imwrite(f\"{save_prefix}dilated.png\", (d_bsIm.astype(np.uint8)*255))\n",
    "    except Exception as e:\n",
    "        print(\"Save skipped:\", e)\n",
    "\n",
    "    return d_bsIm\n",
    "\n",
    "run_q4(masks['T=3.0'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1d3de",
   "metadata": {},
   "source": [
    "**Discussion**: We applied binary dilation with a 3×3 ones structuring element to the Q3 mask. As expected, dilation grew the foreground—7074 → 16233 pixels (Δ=+9159)—thickening object regions and bridging small gaps; see q4_dilated.png."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e70db4",
   "metadata": {},
   "source": [
    "**Problem 5**: Next perform a connected components algorithm, and keep only the largest region in\n",
    "L (save/display as an image). [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355bf6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilation (3x3): foreground pixels 7074 -> 16233  (Δ=+9159)\n",
      "Q5: regions=411 | largest area=9336.0 px\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_q5(dilated_mask, save_prefix=\"q5_\"):\n",
    "    # 1) label components (8-connected)\n",
    "    labels = label(dilated_mask.astype(bool), connectivity=2)\n",
    "    props  = regionprops(labels)\n",
    "\n",
    "    if len(props) == 0:\n",
    "        print(\"No regions found.\")\n",
    "        only_big = np.zeros_like(dilated_mask, dtype=np.uint8)\n",
    "        return only_big, labels, None\n",
    "\n",
    "    # 2) pick largest by area (slides: area = # of 1-pixels) \n",
    "    #    and make a binary image with only that region\n",
    "    largest = max(props, key=lambda r: r.area)  # area in pixels\n",
    "    big_id  = largest.label\n",
    "    only_big = (labels == big_id).astype(np.uint8)\n",
    "\n",
    "    # 3) stats + save\n",
    "    print(f\"Q5: regions={len(props)} | largest area={largest.area} px\")\n",
    "    imageio.imwrite(f\"{save_prefix}largest.png\", only_big*255)\n",
    "\n",
    "    # optional: save a bbox overlay for your report\n",
    "    try:\n",
    "        minr, minc, maxr, maxc = largest.bbox  # bounding box corners\n",
    "        box = only_big.copy()\n",
    "        box[minr:maxr, [minc, maxc-1]] = 1\n",
    "        box[[minr, maxr-1], minc:maxc] = 1\n",
    "        imageio.imwrite(f\"{save_prefix}largest_bbox.png\", box*255)\n",
    "    except Exception as e:\n",
    "        print(\"BBox save skipped:\", e)\n",
    "\n",
    "    return only_big, labels, largest\n",
    "\n",
    "# Use the dilated mask from Q4 (we chose T=3.0 in Q3)\n",
    "dil = run_q4(masks[\"T=3.0\"])         # or load q4_dilated.png > 0\n",
    "big, labels, largest = run_q5(dil, save_prefix=\"q5_\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb7cbb8",
   "metadata": {},
   "source": [
    "**Discussion**: We labeled the dilated mask with 8-connected components and kept only the largest region. Out of 411 regions, the largest had 9,336 px, which cleanly isolates the main foreground object while discarding small fragments. Area is just the count of foreground pixels, so this matches the slides’ “keep-largest-blob” heuristic; see q5_largest.png (and the optional bbox overlay)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
